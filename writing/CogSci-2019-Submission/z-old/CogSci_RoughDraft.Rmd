---
title: "Developmental changes in the ability to draw distinctive features of object categories"
bibliography: kiddraw_2019.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

# author-information: >
#     \author{{\large \bf Bria Long} \\ \texttt{bria@stanford.edu} \\ Department of Psychology \\ Stanford University
#     \And {\large \bf Judith E. Fan} \\ \texttt{jefan@stanford.edu} \\ Department of Psychology \\ Stanford University
#     \And {\large \bf Zixian Chai} \\ \texttt{zchai14@stanford.edu} \\ Department of Psychology \\ Stanford University
#     \And {\large \bf Michael C. Frank } \\ \texttt{mcfrank@stanford.edu} \\ Department of Psychology \\ Stanford University}

abstract:
    ""

keywords:
    "object representations; drawings; child development"

output: cogsci2016::cogsci_paper
---

\newcommand{\wrapmf}[1]{#1} 

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T, dev = "cairo_pdf")
```

```{r, libraries}
library(knitr)
library(tidyverse)
library(assertthat)
library(ggthemes)
library(langcog)
library(forcats)
library(egg)
library(gridExtra)
library(reticulate)
library(readr)
library(ggplot2)
library(reshape2)
library(lme4)
library(stringr)
library(viridis)
theme_set(theme_few())
```

# Introduction
Almost every child learns to draw, providing a rich source of potential insight into their emerging understanding of the world around them. Indeed, drawings have been used as method for probing developmental change on a variety of topics [@piaget1929child], including knowledge about geometrical relationships [@Villarroel2017], typical object colors [@Sasaki2016],  representations of living things [@Villarroel_2013], as well as broader, socially relevant constructs, including family attachement relationships [@fury1997children] or cultural norms [@Baluch_2017]. 

Thus as children learn the diagnostic properties of different object categories, they may also express this knowledge in the drawings they make. Indeed, drawings have also long provided inspiration for scientists investigating the representation of object concepts in early life [@minsky1972artifcial]. For example, even when drawing from life, children tend to include features invisible visible from their vantage point but diagnostic of category membership (e.g., a handle on a mug [@bremmer1984prior, @barrett1976symbolism], hinting at a systematic relationship between children's knowledge and the feuatres they include in their drwaings. Furthermore, drawings from semantic dementia patients [@bozeat2003duck] are characterized by a lack of these same kinds distincitve features.

However, asessing whether children's drawings include more distinctive features across childhood has been methodologically challenging for (at least) three reasons. First, while it is easy to hand-pick distinctive features for a few specific categories (e.g., handles for mugs), doing so for the all of the distinctive features from the wealth of categories that children draw is intractable. Furthermore, whether a given feature is present or absent in a drawing can sometimes be ambigous. Second, while children's knowledge about object categories may be changing throughout childhood [@mash2006; for reviews see @juttner2016developmental; @nishimura2009] so is their ability to plan and control their fine-grained motor movements, which undoubtedly explain a portion of any developmental changes in children's drawings [@rehrig2018does]. Finally, as there are likely to be large individual differences in overall drawing ability or fine-motor control within a given age group, conclusions from small, laboratory-based samples may be somewhat limited.

Here, we tackle these challenges to investigate how children's repesentations of object categories change throughou childhood. First, we collect a large-scale dataset of children's drawings of common object categories. To do so, we installed a free-standing drawing station with a digital tablet in a local science museum. So far, this station has allowed us to collect over then thousand drawings for analysis, allowing us to examine at scale how drawings of objects change throughout chilhood.  Second, to analyze changes in the visual features of children's drawings, we capitalize on recent work in recent work that has validated the use of pre-trained deep convolutional neural network (DCNN) models to measure high-level perceptual information in drawings [@fan2015common] as well as children's drawings [@long2018drawings]. Higher layers of these models both capture adult perceptual judgments of object shape similarity [@kubilius2016deep] and predict neural population responses in categories throughout object-selective cortex [@yamins2014performance]. Thus, features learned by these models provide a principled choice of basis for extracting perceptual features useful for inferring object identity from children's drawings. Finally, we develop and validate metrics for assessing fine motor control from a tracing task also embedded in the drawing station, allowing us to examine the contribution of this factor to changes in children's drawings.

We begin the analysis of this dataset with three main goals. In recent work [@long2018drawings] with a smaller sample of drawings, the recognizaiblty of children's drawings increased across childhood, and these changes in recognizabilty were paralleled by changes in the representations of children's drawings in these high-level visual features. Thus, here we first aim to both replicate and unify these findings by directly (1) examining if the intended category of children's drawings can be read out from these high-level features using a linear classifier and (2) if classifier performance increases with age. Second, we develop metrics for evaluating tracing abilities and apply these to examine the relationship children's tracing performance and classifier performance. Finally, to give insight into the kinds of changes that may explain this age-related gain in recognizability, we explore developmental changes changes in how children's drawings are represented in high-level visual feature space. 

```{r load-classifications}
## Load classification data
classification_data <- read.csv('../../data/cogsci_2019/classification-outputs/Classification_Outputs1985.csv') %>%
  as.tibble() %>%
  mutate(session_id = paste('cdm_',session_id,sep="")) %>%
  mutate(age_numeric = age) %>%
  mutate(age = paste('age',age,sep="")) %>%
  mutate(age = as.factor(age)) %>%
  mutate(category = target_label) %>% 
  mutate(image_name = paste(category,'_sketch_', age,'_', session_id,'.png',sep="")) %>%
  select(-X) 
```

```{r load-metadata}

practice_categories = c('shape','this circle','square','this square','something you love')
extra_prompt = c('something you love')

## Load in meta data from mongo-db database dumps
meta_cdm_run_v4 <- read.csv('../../data/cogsci_2019/mongodb-output/MuseumStation_AllDescriptives_7200_images_cdm_run_v4.csv') %>%
  as.tibble() 

all_meta_data <- read.csv('../../data/cogsci_2019/mongodb-output/MuseumStation_AllDescriptives_20780_images_final_cdm_run_v3.csv') %>%
  as.tibble() %>%
  full_join(meta_cdm_run_v4) %>%
  filter(!category %in% practice_categories) %>%
  filter(!category %in% extra_prompt) %>%
  mutate(category_long = category) %>%
  mutate(category = str_split_fixed(category," ",2)[,2]) 

## join with classification data
d <- classification_data %>%
  left_join(all_meta_data) 
```

# Methods
### Drawing Task Procedure
We implemented a web-based drawing game in HTML/Javascript using the paper.js library and collected drawings using a touchscreen tablet on the floor of the museum;  each participant sat in front of this table-mounted touchscreen display. At the beginning of each session, children completed two tracing trials (square, complex shape) and one copying trial (square or circle), designed to assess their ability to coordinate their motor movements (see Tracing Evaluation). After the tracing trails, on each trial, a video of an experimenter verbally prompted children to draw a particular object category (e.g., “What about a dog? Can you draw a dog?”); children had up to 30 seconds to complete their drawings with their fingers. The timimg and position of each stroke was saved to an online database and permitting the calculating of the overall time spent drawing, the amount of ink used, and the number of strokes made as basic covariates.

Stimuli were videos an experimenter verbally referring to 23 common object categories: house, couch, chair, airplane, bike, car, boat, train, bear, cat, rabbit, dog, sheep, bird, frog, fish, person, tree, bowl, phone, cup, scissors, and key. Participants could draw a maximum of 8 stimuli per session, which were part of the drawing station for several months at a time. These categories were chosen to be likely familiar to children, to cover a wide range of superordinate categories, and to vary in the degree to which they are commonly practiced in drawings by children. 

### Data Filtering
Raw drawing data (N=15594 drawings) were conservatively screened for task compliance using a combination of manual and automated procedures (i.e., excluding blank drawings, pure scribbles, and drawings containing words), resulting in the exclusion of 23.8% of all drawings. We adopted conservative screening procedures to ensure that any age-related trends we observed were not due to differences in task compliance across age. Similarily, while viewing a first subset of the drawings, we noticed many very stylized drawings by our youngest participants (2-year-olds); thus, in later versions of the drawing station, we presented participants with an optional survey to indicate if either another child or an adult had also drawn during the session; all drawings where inteference was reported were excluded from analyses (5.12% of participants) and are not reported in the counts above.

### Participants
After filtering, we analyzed data from N=`r length(unique(d$session_id))` children who were on average`r round(mean(d$age_numeric),2)` years of age (range 2-10 years); participants age was self-reported and no other identifying information was collected. 

```{r descriptives-across-age}
### How do our covariates change with age? Compute CIs and plot next to accuracy.
base_size_chosen=16 # size of text in plots

## first summarize data  
cor_by_age <- d %>%
  group_by(age_numeric,category) %>%
  summarize(avg_cor = mean(correct_or_not)) %>%
  group_by(age_numeric) %>%
  multi_boot_standard(col = "avg_cor")  

draw_duration <- d %>%
  group_by(age_numeric,category) %>%
  summarize(avg_num_strokes = mean(num_strokes), avg_draw_duration = mean(draw_duration_old), avg_intensity = mean(mean_intensity)) %>%
  group_by(age_numeric) %>%
  multi_boot_standard(col = "avg_draw_duration")

num_strokes <- d %>%
  group_by(age_numeric,category) %>%
  summarize(avg_num_strokes = mean(num_strokes), avg_draw_duration = mean(draw_duration_old), avg_intensity = mean(mean_intensity)) %>%
  group_by(age_numeric) %>%
  multi_boot_standard(col = "avg_num_strokes") 

avg_intensity <- d %>%
  group_by(age_numeric,category) %>%
  summarize(avg_num_strokes = mean(num_strokes), avg_draw_duration = mean(draw_duration_old), avg_intensity = mean(mean_intensity)) %>%
  group_by(age_numeric) %>%
  multi_boot_standard(col = "avg_intensity")

###
cor_by_age_plot_A = ggplot(cor_by_age, aes(age_numeric,mean, color=age_numeric)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  theme_few(base_size = base_size_chosen) + 
  labs(x='Age', y='Classification accuracy') +
  scale_color_viridis(option="D") + 
  theme(legend.position = "none") + 
  geom_smooth(col='grey',span=10) +
  ggtitle('A')

p1=ggplot(draw_duration, aes(age_numeric,mean, color=age_numeric)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Draw duration') +
  scale_color_viridis(option="D") +
  theme(legend.position = "none") + 
  geom_smooth(col='grey', span = 10) +
  ggtitle('B')

p2=ggplot(avg_intensity, aes(age_numeric,mean, color=age_numeric)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Ink used') +
  scale_color_viridis(option="D") +
  theme(legend.position = "none") + 
  geom_smooth(col='grey', span = 10)  +
  ggtitle('C')

p3=ggplot(num_strokes, aes(age_numeric,mean, color=age_numeric)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Num Strokes') +
  scale_color_viridis(option="D") +
  theme(legend.position = "none") + 
  geom_smooth(col='grey', span = 10)  +
  ggtitle('D')
```

```{r mainResults, fig.env="figure", fig.fullwidth=TRUE, fig.cap = "Leave-one-out classification accuracy (A), the amount of time spent drawing in seconds (B), the amount of ink used (i.e., mean intensity of the drawings) (C), and the number of strokes used (D) are plotted as a function of children’s age. "}
ggarrange(cor_by_age_plot_A,p1,p2,p3, nrow = 1)
```

```{r inferential-stats-1}
## INFERENTIAL STATS - Accuracy
mod_covariates <- glmer(correct_or_not ~ scale(age_numeric) +
                          scale(draw_duration_old) +
                          scale(mean_intensity) +
                          scale(num_strokes) +
                        (1|session_id) +
                        (1|category),
      data = d, family="binomial")
mod_covariates_out=summary(mod_covariates)
# kable(summary(mod_covariates)$coef, digits = 3)
```

```{r exampleDrawings, fig.env = "figure*", fig.pos = "h", out.width="100%", fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example drawings made by children ages 4-10 of several object categories."}
img <- png::readPNG("images/drawings_by_classification_figure.png")
grid::grid.raster(img)
```

```{r inferential-stats-2}
## INFERENTIAL STATS - Probabilities
d_correct <- d %>%
  filter(correct_or_not == 1)

mod_covariates_correct_only <- lmer(target_label_prob ~ scale(age_numeric) +
                          scale(draw_duration_old) +
                          scale(mean_intensity) +
                          scale(num_strokes) +
                        (1|session_id) +
                        (1|category),
      data = d_correct)
mod_covariates_correct_only_out=summary(mod_covariates_correct_only)
# kable(summary(mod_covariates_correct_only)$coef, digits = 3)
```


### Tracing Evaluation

### Deep Convolutional Neural Network Model
We used a standard, pre-trained implementation of the VGG-19 architecture [@simonyan2014very] to extract features from sketches at the last full-connected layer of the network known to support category recognition in both photos. Eeach image elicits a pattern of feature activations (here, 4096 features per image). Features were normalized across the entire image set before analysis (but not normalized within each category or age group). These features form a common basis for representing complex shape similarity -- including the presence of diagnostic object parts (e.g., legs, handles) -- and a basis from which object identity can be easily derived [@kubilius2016deep].

### Logistic Regression Classifier
We used the features extracted by VGG-19 to train a 23-way logistic regression model under leave-one-out cross-validation to estimate the recognizability of drawings produced by children in each age group; importantly, this model had no information about the age of the drawer but was randomly under sampled such that there were an equal number images for each of the 23 categories. This iterative modeling procedure yielded a both a binary classification score for each image as well as the probability that each image was assigned to each category in the dataset.

###  Model Fitting
We anticipated that their drawings may also vary along other dimensions more directly related to the motor production demands of the task, such as the amount of time spent drawing, the number of strokes used, and amount of ink (i.e., mean pixel intensity of sketch). In order to assess whether children’s ability to produce recognizable drawings increased with age, independent of these low-level covariates, we fit a generalized linear mixed-effects model, with scaled age (specified in years), drawing duration, amount of ink used, and number of strokes as fixed effects, and with random intercepts for each individual child and object category. The dependent variable was whether the linear classifier was able to correctly classify the drawing or the probability assigned to the target category

### Feature Space Metrics
To explore changes in the visual features of these drawings, for each age group and object category, we computed the mean feature vector (category center), as well as the root-mean-squared deviation of drawings from their category center using eucildean distance (category dispersion). For each pair of object categories within each age, we used these two metrics  to compute a high-dimensional analogue of d-prime (distinctiveness). The overall change in the size of the feature space was measured by computing the the root-mean-squared deviation of category-centers from the overall grand mean of this feature space (overall dispersion). 

For representational similarity analysis, the Pearson correlation distances between these average feature vectors for each category was computed [@kriegeskorte2008RSA] to contruct 23x23 representational dissimilarity matrices (RDM); these RDMs provide a compact description of the layout of these cateogries in the high-dimensional feature space. Following @kriegeskorte2008RSA, we computed the Spearman rank correlations between the RDMs between at each age vs. the oldest children in our sample (10-year-olds). Estimates of standard error for the both the Spearman correlation between RDMs, were generated by jackknife resampling of the 23 object categories. 

```{r read-python-outputs}

###
rdm_corr <- read.csv('../../data/cogsci_2019/feature_space_metrics/rdm_corr_by_age_dec13.csv') %>%
  as.tibble() %>%
  mutate(age = X + 2) %>%
  mutate(se_lower = rdm_corr_avg - rdm_corr_sem, se_upper = rdm_corr_avg + rdm_corr_sem)

###
dprime <- read.csv('../../data/cogsci_2019/feature_space_metrics/dprime_by_age_dec13.csv') %>%
  as.tibble() %>%
  mutate(age = X + 2) %>%
  mutate(se_lower = dprime_avg - dprime_sem, se_upper = dprime_avg + dprime_sem)

####
dispersions <- read.csv('../../data/cogsci_2019/feature_space_metrics/class_dispersion_by_age_dec13.csv') %>%
  as.tibble()

dispersions = gather(dispersions, category, rmse, -X)
dispersions <- dispersions %>%
  mutate(age = X + 2) %>%
  select(-X)

#####
expansion <- read.csv('../../data/cogsci_2019/feature_space_metrics/distances_jacknifed_age_means_dec13.csv') %>%
  as.tibble() 

expansion = gather(expansion, category, dist_to_center, -X)
expansion <- expansion %>%
  mutate(age = X + 2) %>%
  select(-X)
```


```{r}


```

```{r layerWise, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Spearman's correlation between representational dissimilarity matrices (RDMs) of drawings produced by adults vs. other adults, adults vs. older children, and between adults vs. younger children at each layer of VGG-19. "}

ggplot(dispersions, aes(x = age, y = rmse, col=category)) +
 geom_point(position = position_dodge(width = .1)) +
 # geom_pointrange(aes(ymin = se_lower, ymax = se_upper)) +
 geom_line() +
 theme_few() +
 labs(y = "Within-category dispersions", x = "Age") +
 scale_x_continuous(breaks = c(2,3,4,5,6,7,8,9)) 

```

```{r}

ggplot(rdm_corr, aes(x = age, y = rdm_corr_avg)) +
 geom_point(position = position_dodge(width = .1)) +
 geom_pointrange(aes(ymin = se_lower, ymax = se_upper)) +
 geom_line() +
 theme_few() +
 labs(y = "Similarity to 10-year-olds", x = "Age") +
 scale_x_continuous(breaks = c(2,3,4,5,6,7,8,9)) 

```



# Results
Overall, we found that the model’s classification accuracy increased with age (see Figure \ref{fig:mainResults}). Further, the average probability assigned to the target category increase with age even when restricting our analyses to drawings that were correctly classified, suggesting that classification confidence also increases with age (see Figure \ref{fig:exampleDrawings} for examples ordered by classification confidence).

Next, we examined the contributions of basic task-covariates (e.g., number of strokes, ink used, time spent drawing) as well as tracing performance to these gains in classification (see Figure \ref{fig:mainResults}). Our mixed-effects model revealed that both the classification accuracy of drawings as well as classification confidence (for correct drawings only) reliably increased with age when accounting for these covariates — tracing ability, the amount of time spent drawing, the number of strokes, and total ink used and accounting for variation across object categories and individual children. (classification accuracy: $\beta$ = `r format(mod_covariates_out$coefficients[2,1],digits=2)`, SE = `r format(mod_covariates_out$coefficients[2,2],digits=2) `, Z = `r format(mod_covariates_out$coefficients[2,3],digits=2)`, classification confidence: $\beta$ = `r format(mod_covariates_correct_only_out$coefficients[2,1],digits=2)`, SE = `r format(mod_covariates_correct_only_out$coefficients[2,2],digits=2) `, Z = `r format(mod_covariates_correct_only_out$coefficients[2,3],digits=2)` ). All model coefficients can be found in Table 1. 

Finally, we also examined the relationship between children's ability to complete a brief tracing task at the beginning of the session and the subsequent recognizability of their drawings. Briefly, tracing performance was evaluated by terms that take into account both the spatial error and shape error in XX metric; this metric was validated on a sample of human-judgements on 2000 tracings (r=XX, p=XX, ...).*

To investigate the underlying source of these changes in recognizability, we examined changes in this feature space across age. First, the degree to which drawings elicited robust, variable responses in this feature space increased with children's age, suggesting that older children's drawings may simply contain more detailed and more variable high-level visual features (stats). Relatedly, we also found that the overall distance between category centers and the average of the feature space increased with age, suggestiong an overall expansion of the feature space with age (stats) Second, as in prior work, we found that the correlation bewteen RDMs generally increased with age, suggesting that part of the gain in category classificaiton across age can be attributed to shifts in the relative positions of the category center (stats.) Finally, we also observed a small but consistent decrease in within-category dispersions decreased with age, as well as an overall increase in visual discriminability (i.e., higher-dimensional analog of d-prime) (mean d-prime across all category pairs, 2-yrs, M=0.3, 3-yrs, M=0.27, 4-yrs, M=0.35, 5-yrs, M=0.42, 6-yrs, M=0.45, 7-yrs, M=0.49, 8-yrs, M=0.49, 9-yrs, M=0.51). 

# General Discussion

Changes in VGG features directly related to gains in classificatino in large-scale dataset, controlling for basic tracing abilities as well as basic motor covariates. Suggests that object children are better able to produce these distinctive features for recognition, perhaps paralleling their emerging perceptual and categorization abilities [cite]

Next steps:
1. Caveats: benefits vs costs of musesumstaion vs. controlled environment; validate results in experimental context

2. Understand item effects -- differneces for some items (couches) vs. more typicall drawn items with drawings that are a bit more arbitrary with respect to the physical object

3. Relate production and recognition (animalgame)

2. Understand which features of objects drive changes in recognition, and how these are related to memory  (link back to semantic dementia )
Understand relative contributions of cultural conventions 

<!-- At the same time, children are also continuously learning about new object categories and their properties. How might this learning affect children's internal representations (and drawings) of different object categories? One possibility is that the bulk of the development change revolves around building more detailed representations: children may be learning the suite of visual features and object parts that are diagnostic of various object categories. On this account, learning what tigers tend to look like does not change children's perceptual representations of cheetahs---or how they draw them. A second possibility is that learning about new categories actually changes the similarity structure of children’s visual object concepts [@goldstone2001altering]. Finally, as children learn about the hierarchical structure of object categories (i.e., living thing--animal--mammal--dog) and their typical properties (e.g., most mammals have four legs) this might differentially change which visual features take precedence in their internal representations. Future work that links children's categorization abilities with their drawing behaviors will help explore these possibilities. -->

<!-- This work integrates novel methods to investigate children's internal representations of object categories and how they are linked to their developing perceptual, cognitive, and motor abilities. We propose that a full understanding of how we come to produce visual abstractions will help uncover the factors that shape adult object representations. -->

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering All data and code for these analyses are available at\ \url{https://github.com/brialorelle/kiddraw}}} \vspace{1em}

# Acknowledgements
????
We thank members of Stanford Language and Cognition lab. This work was funded by an NSF SPRF-FR Grant #1714726 to BLL and a Jacobs Foundation Fellowship to MCF. 

# References
```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in}
\setlength{\leftskip}{0.125in}
\noindent





