{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## libraries\n",
    "from __future__ import division\n",
    "\n",
    "##\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "\n",
    "## scikit learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "## for rebalancing datasetes\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ###### \n",
    "# modify paths here\n",
    "def load_features(cohort, layer_num):\n",
    "    layers = ['P1','P2','P3','P4','P5','FC6','FC7']    \n",
    "    F = np.load('srcd-features/museumstation_features/FEATURES_{}_{}_Spatial_True.npy'.format(layers[layer_num],cohort))\n",
    "    M = pd.read_csv('srcd-features/museumstation_features/METADATA_{}.csv'.format(cohort)) \n",
    "    M = M[['label','age','session']]\n",
    "    return F, M\n",
    "\n",
    "## which layer?\n",
    "layer_ind = 6\n",
    "\n",
    "###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ###### ######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load in features\n",
    "KF, KM = load_features('kid',layer_ind)\n",
    "\n",
    "## Randomly downsample the full dataset so that we have an even number of classes (not necessarily by age)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "KF_downsampled, class_labels_downsampled = rus.fit_resample(KF, KM['label'].values)\n",
    "new_samples_ind = rus.sample_indices_\n",
    "KM_downsampled = KM.loc[new_samples_ind]\n",
    "KM_downsampled.to_csv('classification-outputs/Resampled-metadata.csv') # save out metadata as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for \n",
    "loo = LeaveOneOut()\n",
    "X = KF_downsampled\n",
    "y = class_labels_downsampled\n",
    "\n",
    "# make empty arrays for scores and probabilities\n",
    "image_scores = np.empty(np.shape(y)[0])\n",
    "image_scores[:]= np.nan\n",
    "\n",
    "num_categories=np.shape(np.unique(class_labels_downsampled))[0]\n",
    "image_probs = np.empty([np.shape(y)[0], num_categories])\n",
    "image_probs[:]= np.nan\n",
    "\n",
    "indexes = []\n",
    "ages = []\n",
    "target_classes = []\n",
    "session_ids = []\n",
    "image_probs_2=[]\n",
    "image_scores_2 =[]\n",
    "target_label_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop index = 386, image score = 1.0\n",
      "loop index = 372, image score = 1.0\n",
      "loop index = 220, image score = 1.0\n",
      "loop index = 476, image score = 1.0\n"
     ]
    }
   ],
   "source": [
    "# go through all images, retrain model, and get prediction\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # higher tolerance and different solver for larger datasets; or else it takes foreverrrr.\n",
    "    clf = linear_model.LogisticRegression(penalty='l2',C=1,tol=.1,solver='sag').fit(X_train, y_train)\n",
    "    \n",
    "    # scores\n",
    "    this_image_score = clf.score(X_test, y_test)\n",
    "    image_scores[test_index] = this_image_score\n",
    "    image_scores_2.append(this_image_score)\n",
    "\n",
    "    # probabilities\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    image_probs[test_index,:] = probs\n",
    "\n",
    "    image_probs_2.append(probs)\n",
    "\n",
    "    ## get metadata - index\n",
    "    test_index_numeric = new_samples_ind[test_index[0]]\n",
    "    indexes.append(test_index_numeric)\n",
    "    \n",
    "    ## target label\n",
    "    target_label = KM_downsampled['label'][test_index_numeric]\n",
    "    target_classes.append(target_label)\n",
    "    \n",
    "    # target probability\n",
    "    target_label_ind = np.where(clf.classes_==target_label)\n",
    "    prob_array = probs[0,target_label_ind]\n",
    "    target_label_prob.append(prob_array[0,0])\n",
    "\n",
    "    # age/sessionid\n",
    "    ages.append(KM_downsampled['age'][test_index_numeric])\n",
    "    session_ids.append(KM_downsampled['session'][test_index_numeric])\n",
    "\n",
    "    # print output just so we know what's happening.\n",
    "    print('loop index = {}, image score = {}'.format(test_index_numeric,this_image_score))\n",
    "\n",
    "    # print it all out in a dataframe so we group metadata with outputs for easy reading into r\n",
    "    if test_index>0:\n",
    "        _data = pd.DataFrame([indexes, ages, target_classes, session_ids, image_scores_2,target_label_prob])\n",
    "        _data = _data.transpose()\n",
    "        _data = _data.astype(object)\n",
    "        _data.columns = ['indexes','ages','target_classes','session_ids','image_scores','target_label_prob']\n",
    "        image_probs_2_df = pd.DataFrame(image_probs)\n",
    "        image_probs_2_df.columns = clf.classes_ + \" prob\"\n",
    "        out = pd.concat([_data,image_probs_2_df], axis=1)\n",
    "        out.to_csv('classification-outputs/museumstation_subset_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(probs[0,target_label_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0824924424120662"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
