{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remember to run conn_cocolab from the terminal before running cells in this notebook!\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File hierarchy and database connection vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'cdm_run_v3'\n",
    "exp_path = 'museumstation'\n",
    "analysis_dir = os.getcwd()\n",
    "exp_dir = os.path.abspath(os.path.join(os.getcwd(),'../..','experiments'))\n",
    "sketch_dir = os.path.join(analysis_dir,'sketches')\n",
    "data_dir = os.path.join(analysis_dir,'usage_data')\n",
    "scribble_dir = os.path.join(analysis_dir,'scribbles')\n",
    "\n",
    "# load data\n",
    "raw_data = pd.read_csv(os.path.join(data_dir, \"scribble_annotate.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['kiddraw']\n",
    "coll = db['cdm_run_v3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportion of black pixels on the png image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixel proportions on each sketch\n",
    "raw_data['num_black_pixels'] = 0\n",
    "raw_data['prop_black'] = 0.0\n",
    "\n",
    "for index, row in raw_data.iterrows():\n",
    "    fname = row.filename\n",
    "    img_name = fname.split('/')[-1]\n",
    "    cat_name = img_name.replace('.png','').split('_')[0]\n",
    "    fpath = os.path.join(scribble_dir, cat_name, img_name)\n",
    "    \n",
    "    sketch = cv2.imread(fpath, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # get the number of all black pixels\n",
    "    pixels_black = np.argwhere(sketch.sum(axis=2) > 0)\n",
    "    num_black_pixels = len(pixels_black)\n",
    "    \n",
    "    # the number of all pixels\n",
    "    num_all_pixels = len(sketch) * len(sketch[0])  # row * col\n",
    "    \n",
    "    raw_data.at[index, 'num_black_pixels'] = num_black_pixels\n",
    "    raw_data.at[index, 'prop_black'] = float(num_black_pixels)/float(num_all_pixels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stroke length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stroke Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6)\n"
     ]
    }
   ],
   "source": [
    "# change age from strings to integers\n",
    "raw_data['age'] = raw_data['age'].str.replace('age','')\n",
    "pd.to_numeric(data.age)\n",
    "\n",
    "# transfer categorical columns into integers\n",
    "raw_data.category = pd.Categorical(raw_data.category)\n",
    "raw_data['cat_code'] = raw_data.category.cat.codes\n",
    "\n",
    "feature_cols = ['cat_code', 'age', 'num_strokes','num_black_pixels', 'prop_black']\n",
    "select_cols = feature_cols[:]\n",
    "select_cols.append('scribble')\n",
    "data = raw_data.loc[:, select_cols]\n",
    "\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 5) (480,)\n",
      "(320, 5) (320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.4)\n",
    "\n",
    "# get features\n",
    "train_x = train.loc[:, feature_cols]\n",
    "test_x = test.loc[:, feature_cols]\n",
    "\n",
    "# get scribble values\n",
    "train_y = train.scribble\n",
    "test_y = test.scribble\n",
    "\n",
    "print train_x.shape, train_y.shape\n",
    "print test_x.shape, test_y.shape\n",
    "\n",
    "# train\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_x, train_y)\n",
    "\n",
    "gbm = GradientBoostingClassifier(min_samples_split=50, min_samples_leaf=10)\n",
    "gbm.fit(train_x, train_y)\n",
    "\n",
    "# prediction on the test set\n",
    "test_pred_log = logreg.predict(test_x)\n",
    "test_pred_gbm = gbm.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.96       282\n",
      "          1       0.83      0.39      0.54        38\n",
      "\n",
      "avg / total       0.91      0.92      0.91       320\n",
      "\n",
      "gradient boosting classifer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.96       282\n",
      "          1       0.75      0.47      0.58        38\n",
      "\n",
      "avg / total       0.91      0.92      0.91       320\n",
      "\n",
      "combination\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       282\n",
      "          1       0.93      0.34      0.50        38\n",
      "\n",
      "avg / total       0.92      0.92      0.90       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluate the model\n",
    "# f1 = f1_score(test_y, test_pred, average='micro')\n",
    "# print 'f1 score: ', f1\n",
    "\n",
    "final_test_pred = np.zeros(len(test_y))\n",
    "                           \n",
    "for i, v in enumerate(test_pred_log):\n",
    "    if v==1 and test_pred_gbm[i]==1:\n",
    "        final_test_pred[i] = 1\n",
    "                           \n",
    "target_names = ['0', '1']\n",
    "print 'logistic regression'\n",
    "print(classification_report(test_y, test_pred_log, target_names=target_names))\n",
    "\n",
    "print 'gradient boosting classifer'\n",
    "print(classification_report(test_y, test_pred_gbm, target_names=target_names))\n",
    "                           \n",
    "print 'combination'\n",
    "print(classification_report(test_y, final_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
