---
title: "PhotoDraw2-RecognitionAnalysis"
author: "Bria Long"
date: "8/6/2018"
output: html_document
---

```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
library(tidyverse)
library(assertthat)
library(ggthemes)
library(lme4)
library(langcog)
library(lmerTest)
library(viridis)
library(jsonlite)
library(egg)
theme_set(theme_few())
```

# Part 1: Setup
### Load in recognition data
```{r message=FALSE}
d.raw <- data.frame()
files <- dir("raw_recognition_data/")
for (f in files) {
  jf <- paste("raw_recognition_data/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- data.frame(workerid = jd$WorkerId, 
                   guessed_category = jd$answers$data$rating,
                   actual_category = jd$answers$data$this_sketch_category,
                   subID = jd$answers$data$drawing_session_id,
                   condition = jd$answers$data$condition,
                   this_sketch_name = jd$answers$data$this_sketch_name,
                   age = jd$answers$data$producer_age,
                   photo_cue = jd$answers$data$photo_cue,
                   chunk = jd$answers$data$chunk,
                   trial_number =jd$answers$data$chunk
                  )
  d.raw <- bind_rows(d.raw, id)
}

```

### Check number of raters per chunk and image
```{r}
raters_per_chunk <- d.raw %>%
  distinct(workerid, chunk) %>%
  group_by(chunk) %>%
  summarize(count = n())

raters_per_image <- d.raw %>%
  distinct(this_sketch_name, workerid) %>%
  group_by(this_sketch_name) %>%
  summarize(count = n())
```

### Make guess/actual cateogries comparable
```{r}
d <- d.raw
d$guessed_category = as.factor(d$guessed_category)
d$actual_category <- factor(d$actual_category, levels=levels(d$guessed_category))

d <- d %>%
  mutate(correct_or_not = (actual_category == guessed_category)) 
```

### Compute bad workers (relaunch hits to replace in batches)
```{r}
prac_thres = 11/12 ## 12 practice trials -- if you missed more than 1, exclude

# compute who didn't pass this threshold
bad_workers <- d %>%
  filter(condition=='practice') %>%
  group_by(workerid, chunk) %>%
  summarize(avg_prac_correct = mean(correct_or_not)) %>%
  filter(avg_prac_correct < prac_thres)

# filter from dataset
d <- d %>%
  filter(!workerid %in% bad_workers$workerid)

raters_per_chunk_filtered <- d %>%
  distinct(workerid, chunk) %>%
  group_by(chunk) %>%
  summarize(count = n())
```

### Compute accuracy for each sketch, averaging over turkers
```{r}
avg_by_sketch <- d %>%
  filter(condition != 'practice') %>%
  mutate(sketch_name = str_split_fixed(this_sketch_name, '/',9)[,9]) %>%
  mutate(sketch_name = as.factor(sketch_name)) %>%
  mutate(correct_or_not = (actual_category == guessed_category)) %>%
  group_by(sketch_name,age,condition,actual_category, subID) %>%
  summarize(avg_sketch_correct = mean(correct_or_not)) # averages over raters
```

### Read in python descriptives and join with recognition ratings
```{r}
sketch_descriptives <- read_csv('sketch_descriptives/Photodraw2_SRCD_cleaned_data_4-8.csv') %>%
  as.tibble() %>%
  mutate(actual_category = as.factor(category)) %>%
  mutate(subID = as.factor(subID)) %>%
  mutate(condition = as.factor(condition)) %>%
  mutate(age = as.factor(age_numeric)) %>%
  mutate(sketch_name = str_split_fixed(filename,'/',12)[,12]) %>%
  mutate(session_id = str_split_fixed(session_id, '_', 2)[,2]) %>%
  mutate(session_id = as.factor(session_id))

joined <- left_join(avg_by_sketch,sketch_descriptives, by =c('sketch_name','subID','age','condition','actual_category'))
```

### Sanity check joining of two datasets
```{r}
unique_sketches <- d %>%
  filter(condition!='practice') %>%
  distinct(this_sketch_name)
 
assert_that(length(unique_sketches$this_sketch_name)==length(joined$sketch_name))
```

# Part 2: Descriptive statistics 
### Take a look at the raw rating data 
Highest chosen category is correct one;  confusions look more or less reasonable.
```{r}
ratingConfusions <- d %>%
  group_by(actual_category, guessed_category)  %>%
  summarize(number = n()) %>%
  group_by(actual_category) %>%
  mutate(prop = number / sum(number)) %>%
  complete(guessed_category, fill = list(prop = 0))

## Plot it
ggplot(ratingConfusions, 
       aes(x = guessed_category, y = actual_category, fill = prop)) + 
  geom_tile() + 
  ylab("True Category") + 
  xlab("Rated as") + 
  scale_fill_viridis(limits = c(0, .6),option="viridis") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
```

### Compute accuracy by condition/age
```{r}
 cond_by_age <- avg_by_sketch %>%
  group_by(subID,condition,age) %>% # group at level of individual subjects/conditions
  summarize(avg_sub_by_cond_correct = mean(avg_sketch_correct)) %>% # average over sketch recognition accuracies
  group_by(age,condition) %>% # group by age/condition
  multi_boot_standard(col='avg_sub_by_cond_correct')  
```

### Plot main results of recognition rtaings
```{r}
ggplot(cond_by_age, aes(x=age, y=mean, col=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5))
```

### Average and plot next to covariates

```{r}
cor_by_age <- joined %>%
  group_by(subID,condition,age_numeric) %>%
  summarize(avg_cor = mean(avg_sketch_correct)) %>%
  group_by(age_numeric,condition) %>%
  multi_boot_standard(col = "avg_cor") 


joined$draw_duration_new[joined$draw_duration_new>30]=30 ## some weird draw durations > 30 seconds?
draw_duration <- joined %>%
  group_by(subID,condition,age_numeric) %>%
  summarize(avg_draw_duration = mean(draw_duration_new)) %>%
  group_by(age_numeric,condition) %>%
  multi_boot_standard(col = "avg_draw_duration")

num_strokes <- joined %>%
  group_by(subID,condition,age_numeric) %>%
  summarize(avg_num_strokes = mean(num_strokes)) %>%
  group_by(age_numeric,condition) %>%
  multi_boot_standard(col = "avg_num_strokes") 

avg_intensity <- joined %>%
  group_by(subID,condition,age_numeric) %>%
  summarize(avg_intensity = mean(mean_intensity)) %>%
  group_by(age_numeric,condition) %>%
  multi_boot_standard(col = "avg_intensity")

# tracing_scores <- d %>%
#   distinct(session_id,age_numeric,avg_tracing_rating) %>%
#   filter(!is.na(avg_tracing_rating)) %>%
#   group_by(age_numeric) %>%
#   multi_boot_standard(col = "avg_tracing_rating")
```


### Make compiled plot with accuracy and descriptives
```{r plot-descriptives-across-age}
## Make compiled plot of descriptives
base_size_chosen=18 # size of text in plots
smooth_alpha=.2

cor_by_age_plot_A = ggplot(cor_by_age, aes(age_numeric,mean, color=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) + 
  theme_few(base_size = base_size_chosen) + 
  labs(x='Age', y='Average adult recognition') +
  # scale_color_viridis(option="D") + 
  theme(legend.position = "none") +
  # geom_smooth(col='grey',span=10, alpha=smooth_alpha) +
  # ggtitle('A') + 
  ylim(0,1) + 
  geom_hline(yintercept = 1/12, linetype="dashed", color="grey")

p1=ggplot(draw_duration, aes(age_numeric,mean, color=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Draw duration (s)') +
  # scale_color_viridis(option="D") +
  theme(legend.position = "none") + 
  ylim(0,20) 
  # geom_smooth(col='grey', span = 10) +
  # ggtitle('B')

p2=ggplot(avg_intensity, aes(age_numeric,mean, color=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Ink used (mean intensity)') +
  # scale_color_viridis(option="D") +
  theme(legend.position = "none") + 
  ylim(.02,.08) 
  # geom_smooth(col='grey', span = 10,alpha=smooth_alpha)  +
  # ggtitle('C')

p3=ggplot(num_strokes, aes(age_numeric,mean, color=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) +
  theme_few(base_size = base_size_chosen) +
  labs(x='Age', y='Number of strokes') +
  # scale_color_viridis(option="D") +
  theme(legend.position = "right") +
  ylim(0,15) 
  # geom_smooth(col='grey', span = 10,alpha=smooth_alpha)  +
  # ggtitle('D')
        
# p4=ggplot(tracing_scores, aes(age_numeric,mean, color=age_numeric)) +
#   geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) +
#   theme_few(base_size = base_size_chosen) +
#   labs(x='Age', y='Normalized tracing score') +
#   # scale_color_viridis(option="D") +
#   theme(legend.position = "none") + 
#   geom_smooth(col='grey', span = 10,alpha=smooth_alpha)  +
#   ggtitle('E')
```
### Render jointed plot
```{r}
ggarrange(cor_by_age_plot_A,p1,p2,p3, nrow = 1)
```


### Look at this condition x age trends for each item
```{r}
category_by_cond <- joined %>%
  group_by(category, age, condition) %>%
  multi_boot_standard(col = 'avg_sketch_correct')

ggplot(category_by_cond,aes(x=age, y=mean, col=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) +
  facet_wrap(~category)
```

### How different are individual participants?
```{r}
## Get proportion recognized for each participant
indiv <- joined %>%
  group_by(subID) %>%
  mutate(sub_correct = mean(avg_sketch_correct)) %>%
  distinct(subID, sub_correct, age) %>% # get unique combos of sessionId and average 
  ungroup() %>%
  mutate(subID = fct_reorder(subID, sub_correct, .desc=TRUE))

## Plot individual children ordered from best to worst
ggplot(indiv, aes(x = subID, y = sub_correct, col = age)) +
  geom_point() +
  theme(axis.text.x = element_blank())+
  xlab("Individual children") +
  ylab("Proportion Recognized") +
  scale_color_viridis(discrete = TRUE) +
  geom_hline(yintercept=1/49, col='grey') # plot chance line

## Plot individual children by age
ggplot(indiv, aes(x = age, y = sub_correct, col = age)) +
  geom_point() +
  xlab("Age") +
  ylab("Proportion Recognized") +
  scale_color_viridis(discrete=TRUE) +
  geom_hline(yintercept=1/22, col='grey') # plot chance line
```

### Look at individual children's differences b/t perception vs. semantic across age
```{r}
corbyChild <- joined %>%
  group_by(condition,subID, age) %>%
  summarize(avgCorrect = mean(avg_sketch_correct)) %>%
  group_by(subID,age) %>%
  summarize(cond_diff = avgCorrect[condition=='P'] - avgCorrect[condition=='S'])

ggplot(corbyChild, aes(x = age, y = cond_diff, col=age)) + 
  geom_jitter(width = .01, alpha = .5)  +
  scale_color_viridis(discrete=TRUE) +
  ylab("P-S")
```

### Plot recognizability x num_strokes and drawing_duration
```{r}
ggplot(joined, aes(x = num_strokes, y = avg_sketch_correct, col=condition)) +
    geom_jitter(width = .1, alpha = .5) +
    facet_grid(~age)

ggplot(joined, aes(x = draw_duration_new, y = avg_sketch_correct, col=condition)) +
    geom_jitter(width = .1, alpha = .5) +
    facet_grid(~age)
```

# Part 3: Inferential Statistics

### Inferential analyses: Non-linear mixed effect model with random slopes for items and random intercepts for participants. 
```{r}

# scale age, make sure condition is a factor
joined$condition=as.factor(joined$condition)

joined$age = as.numeric(joined$age)
joined$age_sc = scale(joined$age, scale = FALSE) # center but don't scale age

#
model_lmer <- lmer(avg_sketch_correct ~ age_sc*condition + (condition | subID) + (condition | category),  data = joined)

model_summary = summary(model_lmer)$coef
kable(model_summary)
```

### Add effort covariates to see how this changes the model
```{r}

#
model_lmer <- lmer(avg_sketch_correct ~ age_sc*condition + draw_duration_new + num_strokes + mean_intensity + (condition | subID) + (condition | category),  data = joined)

model_summary = summary(model_lmer)$coef
kable(model_summary)
```

### Check residuals of the model
Seem relatively evenly distributed around zero; suggests lmer isn't *too* bad of a fit -- maybe should use glmer though
```{r}
plot(joined$age,resid(model_lmer))
plot(joined$condition,resid(model_lmer))
```


# Part 4: Compare human vs machine classification

### Load classificaitons
```{r load-classifications}
classification_data <- read.csv('compiled_classifications/Classification_Outputs1200.csv') %>%
  as.tibble() %>%
  mutate(category = target_label) %>% 
  select(-X) 
```

### Join with human classifiation data (sizes will be different since some sketches eliminated for balancing by category)
```{r}
all <- joined %>%
  left_join(classification_data)
```

### Plot human classifications vs. machine classifications 
```{r}
ggplot(all, aes(x=avg_sketch_correct, y=correct_or_not, col=actual_category)) +
  geom_jitter(width=.01, height=.01, alpha=.5) +
  facet_wrap(~actual_category) + 
  geom_smooth() + 
  xlab('avg human accuracy') + 
  ylab('classification accuracy')

```

### Plot human classifications vs. machine target probability (graded measure of accuracy) 
```{r}
ggplot(all, aes(x=avg_sketch_correct, y=target_label_prob, col=actual_category)) +
  geom_jitter(width=.01, alpha=.5) +
  facet_wrap(~actual_category) + 
  geom_smooth() + 
  xlab('avg human accuracy') + 
  ylab('classification probability')
```

### Compare humans vs. machines for main contrast of interest
```{r}
compare <- all %>%
  group_by(session_id,age,condition) %>%
  summarize(machine = mean(correct_or_not, na.rm=TRUE), human = mean(avg_sketch_correct)) 

compare <- gather(compare, value="accuracy", key="which_classifier", machine, human)
compare$which_classifier <- as.factor(compare$which_classifier)

age_by_cond <- compare %>%
  filter(!is.na(accuracy)) %>%
  group_by(condition,age,which_classifier) %>%
  multi_boot_standard(col='accuracy')

ggplot(age_by_cond, aes(x=age, y=mean, col=condition)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = 0.5)) +
  facet_wrap(~which_classifier) 
  scale_color_brewer(palette="Dark2")
```
