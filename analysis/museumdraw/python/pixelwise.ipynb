{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, imsize=224, volatile=True, use_cuda=False):\n",
    "    im = Image.open(path)\n",
    "    im = RGBA2RGB(im)\n",
    "\n",
    "    # crop to sketch only (eliminate white space)\n",
    "    arr = np.asarray(im)\n",
    "    w,h,d = np.where(arr<255) # where the image is not white\n",
    "    if len(h)==0:\n",
    "        print(path)            \n",
    "    xlb = min(h)\n",
    "    xub = max(h)\n",
    "    ylb = min(w)\n",
    "    yub = max(w)\n",
    "    lb = min([xlb,ylb])\n",
    "    ub = max([xub,yub])            \n",
    "    im = im.crop((lb, lb, ub, ub))            \n",
    "\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Pad(padding),                \n",
    "        transforms.Scale(imsize),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    im = Variable(loader(im), volatile=volatile)\n",
    "    im = im.unsqueeze(0)\n",
    "    return im \n",
    "\n",
    "        \n",
    "def RGBA2RGB(image, color=(255, 255, 255)):\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(paths, imsize):\n",
    "    for path in paths:\n",
    "        image = load_image(path)\n",
    "        label, age, session = get_metadata_from_path(path)\n",
    "        yield (image, label, age, session)       \n",
    "\n",
    "def list_files(path, ext='png'):\n",
    "        result = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "        return result\n",
    "\n",
    "def RGBA2RGB(image, color=(255, 255, 255)):\n",
    "    \"\"\"Alpha composite an RGBA Image with a specified color.\n",
    "    Simpler, faster version than the solutions above.\n",
    "    Source: http://stackoverflow.com/a/9459208/284318\n",
    "    Keyword Arguments:\n",
    "    image -- PIL RGBA Image object\n",
    "    color -- Tuple r, g, b (default 255, 255, 255)\n",
    "    \"\"\"\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scratch pad to outline pixel extraction\n",
    "data_path = '/data2/jefan/quickDraw/png_micro'\n",
    "all_pngs = list_files(data_path)\n",
    "imSize=224\n",
    "numPixels=imSize*imSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_path(path,cohort):\n",
    "    label = path.split('/')[-2]            \n",
    "    if cohort == 'kid':\n",
    "        age = path.split('/')[-1].split('_')[2]\n",
    "        session = path.split('/')[-1].split('.')[0].split('_')[-2] + '_' + path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    elif cohort == 'adult':\n",
    "        age = 'adult'\n",
    "        session = 'unknown'\n",
    "    else:\n",
    "        print('Need to specify a cohort: \"kid\" or \"adult\"!')\n",
    "        age = 'unknown'\n",
    "        session = 'unknown'\n",
    "    return label, age, session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adult features\n",
    "Labels = []\n",
    "Ages = []\n",
    "Sessions = []\n",
    "Features = np.zeros((len(all_pngs),numPixels))\n",
    "\n",
    "for vi, v in enumerate(np.asarray(all_pngs)):\n",
    "    im = Image.open(v)\n",
    "    im = RGBA2RGB(im)\n",
    "    im2 = im.resize((224,224), Image.ANTIALIAS)\n",
    "    arr = np.array(im2)\n",
    "    oneChannel = arr[:,:,1];\n",
    "    pixels = np.ravel(oneChannel)\n",
    "    Features[vi,:] = pixels\n",
    "    label, age, session = get_metadata_from_path(v,'adult')\n",
    "    Labels.append(label)\n",
    "    Ages.append(age)\n",
    "    Sessions.append(session)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save adult pixels\n",
    "save_path = '/home/bria/kiddraw/analysis/museumdraw/python/features/FEATURES_pixel_adult'\n",
    "np.save(save_path, Features)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Labels':  Labels,\n",
    "    'Ages': Ages,\n",
    "    'Sessions': Sessions\n",
    "})\n",
    "\n",
    "save_path_csv = '/home/bria/kiddraw/analysis/museumdraw/python/features/METADATA_ADULT_Pixels'\n",
    "df.to_csv(save_path_csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefan/kiddraw/analysis/museumdraw/sketches/banana/banana_sketch_8_E1c_1511300355318.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now for kid features\n",
    "data_path_kids = '/home/jefan/kiddraw/analysis/museumdraw/sketches'\n",
    "all_pngs_kids = list_files(data_path_kids)\n",
    "\n",
    "all_pngs_kids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kid features\n",
    "Labels = []\n",
    "Ages = []\n",
    "Sessions = []\n",
    "Features = np.zeros((len(all_pngs_kids),numPixels))\n",
    "\n",
    "for vi, v in enumerate(np.asarray(all_pngs_kids)):\n",
    "    im = Image.open(v)\n",
    "    im = RGBA2RGB(im)\n",
    "    im2 = im.resize((224,224), Image.ANTIALIAS)\n",
    "    arr = np.array(im2)\n",
    "    oneChannel = arr[:,:,1];\n",
    "    pixels = np.ravel(oneChannel)\n",
    "    Features[vi,:] = pixels\n",
    "    label, age, session = get_metadata_from_path(v,'kid')\n",
    "    Labels.append(label)\n",
    "    Ages.append(age)\n",
    "    Sessions.append(session)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path_kid = '/home/bria/kiddraw/analysis/museumdraw/python/features/FEATURES_pixel_kid'\n",
    "np.save(save_path_kid, Features)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Labels':  Labels,\n",
    "    'Ages': Ages,\n",
    "    'Sessions': Sessions\n",
    "})\n",
    "\n",
    "save_path_csv_kid = '/home/bria/kiddraw/analysis/museumdraw/python/features/METADATA_KID_Pixels'\n",
    "df.to_csv(save_path_csv_kid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
