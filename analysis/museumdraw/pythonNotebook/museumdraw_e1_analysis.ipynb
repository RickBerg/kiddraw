{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## remember to run conn_cocolab from the terminal before running cells in this notebook!\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file hierarchy and database connection vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'e1'\n",
    "exp_path = 'museumdraw'\n",
    "analysis_dir = os.getcwd()\n",
    "exp_dir = os.path.abspath(os.path.join(os.getcwd(),'../..','experiments'))\n",
    "##\n",
    "sketch_dir = os.path.join(analysis_dir,'sketches')\n",
    "if not os.path.exists(sketch_dir):\n",
    "    os.makedirs(sketch_dir)\n",
    "## dir where we can keep all sketches not binned by category    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['kiddraw']\n",
    "coll = db['E1c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render out all pngs you can find!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "really_run = 1\n",
    "if really_run:\n",
    "    final_images = coll.find({'dataType':'finalImage'}).sort('time')\n",
    "    imsize = 224\n",
    "    for rec in final_images:\n",
    "        imgData = rec['imgData'];\n",
    "        filestr = base64.b64decode(imgData)\n",
    "        if rec['time']> 1510252452134: ## this is the timepoint after which real data started getting collected\n",
    "            if 'age' in rec.keys():\n",
    "                category_dir = os.path.join(sketch_dir,rec['category'])\n",
    "                if not os.path.exists(category_dir):\n",
    "                    os.makedirs(category_dir)\n",
    "                fname = os.path.join(category_dir,'{}_sketch_{}_{}.png'.format(rec['category'], rec['age'],rec['sessionId']))\n",
    "                with open(fname, \"wb\") as fh:\n",
    "                    fh.write(imgData.decode('base64'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "The collection that contains the data we will analyze for VSS is called 'E1c'. There were 16 categories in this set. \n",
    "\n",
    "12/19/17: We expanded the set of classes from 16 classes to 22 classes. These are saved under the experiment name 'E1d.'\n",
    "\n",
    "There are two types of records in the database: 'stroke' and 'finalImage'. This is stored under the key: 'dataType'.\n",
    "The 'stroke'-type of record contains the svg string information. Every stroke event is stored as a separate record.\n",
    "The session identifier is called \"sessionId\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_name = 'E1c'\n",
    "time_threshold = 1510252452134 ## this is the timepoint after which real data started getting collected\n",
    "all_sessions = coll.distinct('sessionId') ## this returns ALL sessions in this collection. we will then filter on time_threshold\n",
    "valid_sessions = coll.find({'time':{'$gt': time_threshold}}).distinct('sessionId')\n",
    "practice_categories = ['circle','triangle']\n",
    "print 'We currently have {} valid sessions.'.format(len(valid_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "really_run_this = 1\n",
    "if really_run_this:\n",
    "    ## desired output: a dataframe that has trials on the rows, and the following columns:\n",
    "    ## category, age, number of strokes, mean_pixel_intensity, bounding_box_coordinates_LTRB, list of strokes, \n",
    "    ## PNG string, submission_time, submission_date\n",
    "    ## to be saved out as a nice tidy CSV\n",
    "    session_id = []\n",
    "    trial_num = []\n",
    "    category = []\n",
    "    age = []\n",
    "    num_strokes = []\n",
    "    mean_pixel_intensity = []\n",
    "    bounding_box_coords = []\n",
    "    svg = []\n",
    "    svg_times = []\n",
    "    png = []\n",
    "    submit_time = []\n",
    "    submit_date = []\n",
    "    draw_duration = []\n",
    "    filename = []\n",
    "    for s in valid_sessions:\n",
    "        if s.split('_')[0]!='stationPilot0': ## ignore if data comes from station pilot\n",
    "            print 'Analyzing {}'.format(s)\n",
    "            image_recs = coll.find({'$and': [{'time': {'$gt': time_threshold}}, {'sessionId':s}, {'dataType':'finalImage'}]}).sort('time')    \n",
    "            for imrec in image_recs:\n",
    "                if imrec['category'] not in practice_categories: ## don't save practice category trials\n",
    "                    stroke_recs = coll.find({'$and': [{'time': {'$gt': time_threshold}}, \n",
    "                                                      {'sessionId':s}, \n",
    "                                                      {'dataType':'stroke'},\n",
    "                                                      {'trialNum': imrec['trialNum']}]}).sort('time')   \n",
    "                    if stroke_recs.count() > 0: ## only include trials if the drawings are not blank            \n",
    "                        session_id.append(imrec['sessionId'])        \n",
    "                        trial_num.append(imrec['trialNum']) \n",
    "                        category.append(imrec['category'])\n",
    "                        age.append(imrec['age'])\n",
    "                        png.append(imrec['imgData'])\n",
    "                        submit_time.append(imrec['time'])\n",
    "                        submit_date.append(imrec['date'])\n",
    "                        filename.append(os.path.join(sketch_dir,'{}_sketch_{}_{}.png'.format(imrec['category'], imrec['age'],imrec['sessionId'])))\n",
    "                        num_strokes.append(stroke_recs.count())\n",
    "                        _svg = [] # this keeps track of the strokes from THIS final image\n",
    "                        _svg_times = []\n",
    "                        for strec in stroke_recs:\n",
    "                            _svg.append(strec['svg'])\n",
    "                            _svg_times.append(strec['time'])\n",
    "                        draw_duration.append((_svg_times[-1] - _svg_times[0])/1000) ## in seconds\n",
    "                        svg.append(_svg)\n",
    "                        svg_times.append(_svg_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if really_run_this:\n",
    "    X = pd.DataFrame([session_id,trial_num,category,age,submit_time,submit_date,num_strokes,svg,svg_times,png,draw_duration,filename])\n",
    "    X = X.transpose()\n",
    "    X.columns = ['session_id','trial_num','category','age','submit_time','submit_date','num_strokes','svg','svg_times','png','draw_duration', 'filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bounding_box(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "if really_run_this:\n",
    "\n",
    "\n",
    "    ## add mean pixel intensity (amount of ink spilled) & bounding box coords \n",
    "    mean_intensity = []\n",
    "    bounding_box = []\n",
    "    imsize = 100\n",
    "    numpix = imsize**2\n",
    "    thresh = 250\n",
    "    for i,_d in X.iterrows():\n",
    "        imgData = _d['png']\n",
    "        filestr = base64.b64decode(imgData)\n",
    "        fname = os.path.join('sketch.png')\n",
    "        with open(fname, \"wb\") as fh:\n",
    "            fh.write(imgData.decode('base64'))\n",
    "        im = Image.open(fname).resize((imsize,imsize))\n",
    "        _im = np.array(im)\n",
    "        mean_intensity.append(len(np.where(_im[:,:,3].flatten()>thresh)[0])/numpix)\n",
    "        # bounding box part\n",
    "        rmin, rmax, cmin, cmax = get_bounding_box(np.array(Image.open(fname)))\n",
    "        bounding_box.append(tuple((rmin, rmax, cmin, cmax)))\n",
    "\n",
    "    ## add to dataframe    \n",
    "    X = X.assign(mean_intensity=pd.Series(mean_intensity).values)\n",
    "    X = X.assign(bounding_box=pd.Series(bounding_box).values)\n",
    "    \n",
    "    # save out csv\n",
    "    X.to_csv('../preprocessed_data/museumdraw_{}_data.csv'.format(experiment_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load drawing metadata csv back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../preprocessed_data/museumdraw_E1c_imageData.csv'\n",
    "X = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "h = plt.hist(X.num_strokes.values,normed=True)\n",
    "plt.ylabel('proportion')\n",
    "plt.xlabel('number of strokes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "h = plt.hist(X.draw_duration.values,normed=True)\n",
    "plt.ylabel('proportion')\n",
    "plt.xlabel('draw duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "seq = np.arange(4,10)\n",
    "sns.barplot(data=X,x='age',y='num_strokes',order=seq,palette=\"Greens_d\")\n",
    "plt.ylabel('number of strokes')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "seq = np.arange(4,10)\n",
    "\n",
    "sns.barplot(data=X,x='age',y='draw_duration',order=seq, palette=\"Greens_d\")\n",
    "plt.ylabel('draw duration (s)')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "seq = np.arange(4,10)\n",
    "sns.barplot(data=X,x='age',y='mean_intensity',order=seq,palette=\"Greens_d\")\n",
    "plt.ylabel('mean pixel intensity')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### vgg feature analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import embedding as emb\n",
    "reload(emb)\n",
    "from embedding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve sketch paths\n",
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "def get_label_from_path(path):\n",
    "    return path.split('.')[-2].split('_')[-1]    \n",
    "\n",
    "def get_trial_from_path(path):\n",
    "    return path.split('_')[-2]\n",
    "\n",
    "def get_subj_from_path(path):\n",
    "    return path.split('/')[1]\n",
    "\n",
    "# extract metadata\n",
    "path_to_sketches = '../sketches'\n",
    "sketch_paths = sorted(list_files(path_to_sketches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## number of sketch paths \n",
    "print 'Number of sketch paths = {}'.format(len(sketch_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## extract features\n",
    "layers = ['P1','P2','P3','P4','P5','FC6','FC7']\n",
    "layer_ind = 6 ### fc6 = 5, fc7 = 6\n",
    "extractor = FeatureExtractor(sketch_paths,layer=layer_ind)\n",
    "Features, Labels, Ages, Sessions = extractor.extract_feature_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## handle trials where we didn't have age information\n",
    "def convert_age(Ages):\n",
    "    ages = []\n",
    "    for a in Ages:\n",
    "        if len(a)>0:\n",
    "            ages.append(int(a))\n",
    "        else:\n",
    "            ages.append(-1)\n",
    "    return ages\n",
    "Ages = convert_age(Ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# organize metadata into dataframe\n",
    "Y = pd.DataFrame([Labels,Ages,Sessions])\n",
    "Y = Y.transpose()\n",
    "Y.columns = ['label','age','session']\n",
    "Y.to_csv('METADATA_{}.csv'.format(layers[layer_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y.age==-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# z-score normalization to \"center\" the sketch embeddings\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def preprocess_features(Features, Y):\n",
    "    # normalize feature vectors & plot full image-level similarity matrix\n",
    "    _Y = Y.sort_values(['label','age','session'])\n",
    "    inds = np.array(_Y.index)\n",
    "    _Features = normalize(Features[inds])\n",
    "    return _Features, _Y\n",
    "\n",
    "def save_features(Features, Labels, X, layer_num):\n",
    "    layers = ['P1','P2','P3','P4','P5','FC6','FC7']\n",
    "    np.save('FEATURES_{}.npy'.format(layers[layer_num]), Features)\n",
    "    np.save('LABELS.npy', Labels)\n",
    "    X.to_csv('METADATA.csv')\n",
    "    return layer_num\n",
    "\n",
    "def get_class_means(X, labels):    \n",
    "    # load in and normalize features \n",
    "    _mu = np.zeros((len(np.unique(labels)), np.shape(X)[1]))        \n",
    "    X = normalize(X)\n",
    "    for vi, v in enumerate(np.unique(np.asarray(labels))):\n",
    "        Xv = X[labels == v]\n",
    "        nv = float(Xv.shape[0])\n",
    "        if nv > 0:\n",
    "            _mu[vi] = Xv.mean(0)\n",
    "    return _mu\n",
    "\n",
    "def normalize_RDM(MAT):\n",
    "    X = MAT - MAT.mean(0).mean(0)\n",
    "    X = X / np.maximum(MAT.std(0).std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def plot_rdm_by_class(Features,X,layer_num):\n",
    "    layers = ['P1','P2','P3','P4','P5','FC6','FC7']        \n",
    "    sns.set_style('white')\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    labels = X.label.values\n",
    "    means = get_class_means(Features, labels)\n",
    "    CORRMAT = np.corrcoef(means)\n",
    "    plt.matshow(CORRMAT)\n",
    "    plt.colorbar()\n",
    "    if not os.path.exists('./plots'):\n",
    "        os.makedirs('./plots')\n",
    "    plt.savefig('./plots/RDM_by_view_{}.pdf'.format(layers[layer_num]))\n",
    "#     plt.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## preprocess\n",
    "_Features, _Y = preprocess_features(Features, Y)\n",
    "\n",
    "\n",
    "## remove data where you dont have age information\n",
    "def remove_nans(Features, Y):\n",
    "    ind = Y.index[(Y['age'] > 0)]\n",
    "    _Y = Y.loc[ind]\n",
    "    _Features = Features[ind.tolist()]\n",
    "    return _Features, _Y\n",
    "\n",
    "_Features, _Y = remove_nans(_Features, _Y)\n",
    "\n",
    "# reset pandas dataframe index\n",
    "_Y = _Y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick classification test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Quick classification test\n",
    "FEAT = _Features\n",
    "LABELS = _Y.label.values\n",
    "AGES = _Y.age.values\n",
    "\n",
    "# single train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    FEAT, LABELS, test_size=0.25, random_state=0)\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print clf.score(X_test, y_test)\n",
    "\n",
    "run_this = 0\n",
    "if run_this:\n",
    "    # cross-validated\n",
    "    clf = linear_model.LogisticRegression(penalty='l2')\n",
    "    scores = cross_val_score(clf, FEAT, LABELS, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## see how recognizability changes with age?\n",
    "\n",
    "scores = []\n",
    "num_samples = []\n",
    "age_range = np.arange(4,11)\n",
    "\n",
    "\n",
    "# width of moving window in # of trials    \n",
    "window_size = 2\n",
    "lb = int(min(_Y.age.values))\n",
    "ub = int(max(_Y.age.values))\n",
    "num_windows = ub-lb-window_size+2 ##     \n",
    "\n",
    "for n in np.arange(num_windows):\n",
    "    start = lb + n\n",
    "    end = lb + n + window_size\n",
    "    ind = _Y.index[(_Y['age'] >= start) & (_Y['age'] < end)]\n",
    "    meta = _Y.loc[ind]\n",
    "    subFeat = _Features[ind.tolist()]\n",
    "\n",
    "    FEAT = subFeat\n",
    "    LABELS = meta.label.values\n",
    "\n",
    "    # single train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        FEAT, LABELS, test_size=0.4, random_state=0)\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "    print '{}-{}y'.format(start, end-1), len(LABELS),clf.score(X_test, y_test)\n",
    "    num_samples.append(len(LABELS))\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "labels = _Y.label.values\n",
    "means = get_class_means(_Features, labels)\n",
    "CORRMAT = np.corrcoef(means)\n",
    "plt.matshow(CORRMAT)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get RDM for older kids (7,8,9,10)\n",
    "\n",
    "ind = _Y.index[_Y['age'] > 6]\n",
    "subY = _Y.loc[ind]\n",
    "subFeat = _Features[ind.tolist()]\n",
    "\n",
    "meta = subY\n",
    "feat = subFeat\n",
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "labels = meta.label.values\n",
    "means = get_class_means(feat, labels)\n",
    "CORRMAT = np.corrcoef(means)\n",
    "plt.matshow(CORRMAT)\n",
    "plt.colorbar()\n",
    "CORRMAT1 = CORRMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get RDM for young kids (3,4,5,6)\n",
    "ind = _Y.index[_Y['age'] <= 6]\n",
    "subY = _Y.loc[ind]\n",
    "subFeat = _Features[ind.tolist()]\n",
    "\n",
    "meta = subY\n",
    "feat = subFeat\n",
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "labels = meta.label.values\n",
    "means = get_class_means(feat, labels)\n",
    "CORRMAT = np.corrcoef(means)\n",
    "plt.matshow(CORRMAT)\n",
    "plt.colorbar()\n",
    "CORRMAT2 = CORRMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "stats.spearmanr(np.ravel(CORRMAT1),np.ravel(CORRMAT2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
