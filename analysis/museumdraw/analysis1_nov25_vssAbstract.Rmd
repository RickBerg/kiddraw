---
title: "KidDraw-Analysis1"
author: "Bria Long"
date: "11/24/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))

```

## Load data and do basic preprocessing.
```{r}
# Source some helper functions
source("/Users/brialong/Documents/GitHub/kiddraw/analysis/museumdraw/helper_code/useful.R")

## Read in data outputs from python - stroke numbers, intensity, bounding boc, etc.
d <- read.csv("preprocessed_data/museumdraw_E1c_imageData.csv");

# get rid of drwaings without age - these were when we were testing the interface.
d <- d %>%
  filter(!is.na(age))

# make new variable name with image name for joining with recognition data
d$imNameShort = paste(d$category, '_sketch','_', d$age,'_', d$session_id,'.png', sep="");        
## Read in data outputs from turk data - true/false recognition with 21AFC
r <- read.csv("preprocessed_data/museumdraw_E1c_recognitionData.csv");

## check we have the right lengths
length(d$session_id)==length(unique(r$imageName));
```
## Take a look at the raw rating data as a sanity check
Highest chosen category is correct one;  confusions look more or less reasonable
```{r}
dataFrameR=as.data.frame(r);

ratingConfusions <- dataFrameR %>%
  dplyr::group_by(category, rating)  %>%
  dplyr::summarize(number = n()) 

ratingConfusions$rating=as.factor(ratingConfusions$rating)
ggplot(ratingConfusions, aes(rating,number, color=rating))+
  geom_point() +
  facet_wrap(~category) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

##  Preprocess data and join datasets
```{r}
# add special column for when people selected "can't tell at all" during ratings; not separated out in current analyses 
r$cantTell=(r$rating=="cannott tell at all")

## Get the percent recognized for each drawing
corbyItem <- r %>%
  dplyr::group_by(imNameShort) %>%
  dplyr::summarize(meanCorrect = mean(correct), propCantTell = mean(cantTell))

## Joint the two datasets together
joint=join(d,corbyItem);

# treat session_id and category as factors 
joint$session_id=as.factor(joint$session_id)
joint$category=as.factor(joint$category)

## for use below with glmer analyses (which never converged...)
joinedRatings=join(r,d)
```
## Basic descriptives
``` {r}
# Number of drawings
numDrawings=length(joint$imNameShort)

# Number of drawers
numDrawers=length(unique(joint$session_id))

# Average age of drawers
avgAge=round(mean(d$age[d$trial_num==2]),2) ## 2 is the first non-practice trial, use d structure here since it is doesn't repeat for each rating trial

# Drawings by category
drawingsByCategory <- joint %>%
  dplyr::group_by(category) %>%
  dplyr::summarize(count = n())

# Drawings by age
ageDescriptives <- joint %>%
  dplyr::group_by(age) %>%
  dplyr::summarize(count = n(), meanCorrect = mean(meanCorrect), propCantTell = mean(propCantTell))

# Percent "can't tell at all" by age category
ageCantTellOut=round(ageDescriptives$propCantTell*100,1) # not reported in abstract, but interesting.

# Percent correct by age category
ageCorrOut=format(round(ageDescriptives$meanCorrect*100,1), nsmall=1)
```

# Exploratory plots
## How much do num_strokes / intensity / duration  covary with eachother?
In all of the following plots, one point = one drawing
```{r, echo=FALSE}
ggplot(d, aes(num_strokes, mean_intensity)) +
  geom_jitter(alpha=.5) + 
  geom_smooth(method="loess", span=2, alpha=.1)

ggplot(d, aes(num_strokes, draw_duration)) +
  geom_jitter(alpha=.5) + 
  geom_smooth(method="loess", span=2, alpha=.1)
```

## Are darker drawings better recognized?
Interesting - probably somewhat up to a point. Last points are creating a big tail on the loess function but probably more ink = more information = better recognized

```{r, echo=FALSE}
ggplot(joint, aes(mean_intensity, meanCorrect, color=category)) + 
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess", span=2, alpha=.1)
```

## Are drawings with more strokes better recognized?

```{r, echo=FALSE}
ggplot(joint, aes(num_strokes, meanCorrect, color=category)) +
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess",span=2, alpha=.1)

```

## Are drawings that take longer better recognized?

```{r, echo=FALSE}
ggplot(joint, aes(draw_duration, meanCorrect, color=category)) +
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess",span=2, alpha=.1) 
```

## Are drawings better recognized with age?

```{r, echo=FALSE}
ggplot(joint, aes(age, meanCorrect)) +
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess",span=2, alpha=.1) 

ggplot(joint, aes(age, meanCorrect, color=category)) +
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess",span=2, alpha=.1) 
```

## How does this trend break down by catergory?
Some items show a stronger trend than others but overall looks good
```{r, echo=FALSE}
ggplot(joint, aes(age, meanCorrect, color=category)) +
  geom_jitter(alpha=.5) +
  geom_smooth(method="loess",span=2, alpha=.5) + 
  facet_wrap(~category)
```

## How much variance is there per participant (i.e., per child drawer?)
Looks like there are some kids that are very bad or very good at drawing, but there is also a fair number of kids with wide distributions

```{r, echo=FALSE}
ggplot(joint, aes(1, meanCorrect)) +
  geom_violin() +
  facet_wrap(~session_id)
```

# Inferential statistics: data preprocessing
``` {r}
# First norm DV by arc sine transformation since it is a proportion
arcSinTransform <- function (data) {
  out = (asin(sqrt(data)))
}
joint$normCorrect=arcSinTransform(joint$meanCorrect)

# Rescale  continuous predictor variables to get rid of warnings when fitting with only ML
colInd <- grep("mean_intensity",names(joint))
joint[,colInd]=scale(joint[,colInd])

rm(colInd); colInd <- grep("draw_duration",names(joint))
joint[,colInd]=scale(joint[,colInd])

rm(colInd); colInd <- grep("num_strokes",names(joint))
joint[,colInd]=scale(joint[,colInd])

rm(colInd); colInd <- grep("age",names(joint))
joint[,colInd]=scale(joint[,colInd])
```

## Inferential statistics: Does recogizability of drawings increase with age?
Fixed effects of age, object cateogry, number of strokes, draw duration, and avg intensity (e.g., amount of ink)
Random effects of subject (session_id). Can't include random slopes (1+category|sessionId) since every child did not draw every category.
```{r}
## Full model first
fullModel=lmer(normCorrect ~ age + category + mean_intensity + num_strokes + draw_duration + (1|session_id), joint, REML = FALSE)

# Check for normality assumptions on residuals
s=summary(fullModel)
hist(s$residuals)
shapiro.test(residuals(fullModel))
qqnorm(s$residuals)

# Full model minus age
noAge=lmer(normCorrect ~ category + mean_intensity + num_strokes+ draw_duration + (1| session_id), joint, REML = FALSE)

## Model testing - model that includes age is better than model without age.
modelOut=anova(fullModel,noAge)
pOut=format.pval(modelOut$`Pr(>Chisq)`[2],1); # these quotes make it hard to embed in text...shorter variable for ease

## Refit model for with REML for reporting betas
fullModelReport=lmer(normCorrect ~ age + category + mean_intensity + num_strokes + draw_duration + (1|session_id), joint, REML = TRUE)

coefOut=coef(summary(fullModelReport))
ageBeta=format(round(coefOut[2,1],2),2)
ageSE=format(round(coefOut[2,2],2),2)
ageZ=format(round(coefOut[2,3],2),2)

```

## Alternative solution - generalized logistic mixed-effects models on raw rating data
Get convergence warnings here even with minimal models -- ugh. -- commented out. If either of you see a better way to do these that I'm missing or have any suggestions I'd be happy to give these another shot.
``` {r}
# joinedRatings$correctNum=as.numeric(joinedRatings$correct)
# 
# fullModel_glmer=glmer(correctNum ~ age + category + mean_intensity + num_strokes + draw_duration + (1+ age|session_id) + (1|category), data = joinedRatings,  family = "binomial")
# 
# reducedModel_glmer=glmer(correctNum ~ age + category + mean_intensity + (1|session_id), data = joinedRatings,  family = "binomial")
# 
# minimalModel_glmer=glmer(correctNum ~ age + category + (1|session_id), data = joinedRatings,  family = "binomial")

```


## VSS ABSTRACT DRAFT
Title options:
"Drawings convey object category information by middle childhood"

"Drawings as a window into the development of object category representations"

"Development of ability to depict object categories"

Abstract:
Drawing is a powerful tool for communicating concepts in visual form — a few well-placed strokes can convey the identity of a person, object, or scene. Prior work has found that deep neural network models of the ventral stream trained purely on photographs also recognized drawings by nonexpert adults, reflecting concordance in abstract representations of object categories in drawings and photos at higher layers in these models (Fan, Yamins, & Turk-Browne, 2015). How do ordinary people become so effective at producing recognizable drawings? Here we examine the trajectory of this learning during childhood. Children (N = `r numDrawers`, *M* = `r avgAge` years, range 4-10 years) participated in an iPad-based drawing game. On each round, they were prompted with a verbal cue to draw one of sixteen familiar objects (e.g., “Can you draw a cup?”). Children drew each object category for 30 seconds, after which they were prompted to either make another drawing or to stop drawing altogether. Afterwards, a group of naive adults (N = `r length(unique(r$workerid))`) were presented with each of the children's drawings (`r numDrawings`) and guessed the identity of the drawn object. Using a linear mixed-effect modeling approach, we found that recognizability of drawings increased reliably with age (b = .`r ageBeta`, SE = `r ageSE`, Z = `r ageZ`), accounting for variation across categories and children, and after accounting for the amount of time spent drawing, number of strokes, and total ink used  (% drawings recognized; chance = 4.8%; $M_{4yrs}$ = `r ageCorrOut[1]`%, $M_{5yrs}$ = `r ageCorrOut[2]`%, $M_{6yrs}$ = `r ageCorrOut[3]`%, $M_{7yrs}$ = `r ageCorrOut[4]`%, $M_{8yrs}$ = `r ageCorrOut[5]`%, $M_{9yrs}$ = `r ageCorrOut[6]`%, $M_{10yrs}$ = `r ageCorrOut[7]`%); removing age from the model significantly decreased the fit as indidcated by likelikhood ratio tests ($X^2$(1) = `r round(modelOut$Chisq[2],2)`, *p* = `r pOut` ).These results suggest that the capacity to quickly produce graphical representations that communicate object category information is highly developed by middle childhood. More broadly, these findings point to visual production tasks as a promising avenue for examining the development of object category representations.


